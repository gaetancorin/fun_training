{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfa7ff56-27bc-4a0c-b3d3-f6857a23bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daff745e-f61b-44fc-8c13-436fe7408933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|   Krish|31.0|         5| 30000|\n",
      "|Sudhansh|30.0|        10| 10000|\n",
      "|   Sunny|29.0|         2| 15000|\n",
      "|  Pierre|35.0|        10| 40000|\n",
      "|  Benoit|55.0|        25| 75000|\n",
      "|   Lucas|45.0|        20| 64000|\n",
      "| Patrick|22.0|         2| 35000|\n",
      "|    NULL|21.0|         5| 40000|\n",
      "| Francis|NULL|      NULL| 75000|\n",
      "|    NULL|NULL|      NULL|  NULL|\n",
      "|    NULL|45.0|      NULL|  NULL|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark.read.option('header', 'true').csv(\"test3.csv\").show()\n",
    "# df_pyspark = spark.read.option('header', 'true').csv(\"test3.csv\")\n",
    "\n",
    "# Une autre manière de faire:\n",
    "spark.read.csv(\"test3.csv\", header=True, inferSchema=True).show()\n",
    "df_pyspark = spark.read.csv(\"test3.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e385669-39ce-4aa4-87af-73c0dfe5bf1f",
   "metadata": {},
   "source": [
    "## Différents types de suppression de NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c274a27-d41d-402d-b19b-31a0868a8a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|   Krish|31.0|         5| 30000|\n",
      "|Sudhansh|30.0|        10| 10000|\n",
      "|   Sunny|29.0|         2| 15000|\n",
      "|  Pierre|35.0|        10| 40000|\n",
      "|  Benoit|55.0|        25| 75000|\n",
      "|   Lucas|45.0|        20| 64000|\n",
      "| Patrick|22.0|         2| 35000|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Supprime l'enregistrement complet si il contient UN OU PLUSIEURS null\n",
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94b5442f-b471-4c2d-95b4-d97745b26bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|   Krish|31.0|         5| 30000|\n",
      "|Sudhansh|30.0|        10| 10000|\n",
      "|   Sunny|29.0|         2| 15000|\n",
      "|  Pierre|35.0|        10| 40000|\n",
      "|  Benoit|55.0|        25| 75000|\n",
      "|   Lucas|45.0|        20| 64000|\n",
      "| Patrick|22.0|         2| 35000|\n",
      "|    NULL|21.0|         5| 40000|\n",
      "| Francis|NULL|      NULL| 75000|\n",
      "|    NULL|45.0|      NULL|  NULL|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Supprime l'enregistrement complet si il ne contient QUE DES null\n",
    "df_pyspark.na.drop(how=\"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "630001c3-8bff-492b-b494-4f9e1a4f94fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|   Krish|31.0|         5| 30000|\n",
      "|Sudhansh|30.0|        10| 10000|\n",
      "|   Sunny|29.0|         2| 15000|\n",
      "|  Pierre|35.0|        10| 40000|\n",
      "|  Benoit|55.0|        25| 75000|\n",
      "|   Lucas|45.0|        20| 64000|\n",
      "| Patrick|22.0|         2| 35000|\n",
      "|    NULL|21.0|         5| 40000|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Supprime l'enregistrement complet si il ne contient QUE DES null SUR LA COLONNE SPECIFIER\n",
    "df_pyspark.na.drop(how=\"all\", subset=['Experience']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f80354-df59-4f53-b00b-c379449930a7",
   "metadata": {},
   "source": [
    "## remplacement de valeurs null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db0e7f72-7d76-4b62-9fed-823ce574531a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+----------+------+\n",
      "|         Name| age|Experience|Salary|\n",
      "+-------------+----+----------+------+\n",
      "|        Krish|31.0|         5| 30000|\n",
      "|     Sudhansh|30.0|        10| 10000|\n",
      "|        Sunny|29.0|         2| 15000|\n",
      "|       Pierre|35.0|        10| 40000|\n",
      "|       Benoit|55.0|        25| 75000|\n",
      "|        Lucas|45.0|        20| 64000|\n",
      "|      Patrick|22.0|         2| 35000|\n",
      "|Missing value|21.0|         5| 40000|\n",
      "|      Francis|NULL|      NULL| 75000|\n",
      "|Missing value|NULL|      NULL|  NULL|\n",
      "|Missing value|45.0|      NULL|  NULL|\n",
      "+-------------+----+----------+------+\n",
      "\n",
      "+--------+----+----------+------+\n",
      "|    Name| age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|   Krish|31.0|         5| 30000|\n",
      "|Sudhansh|30.0|        10| 10000|\n",
      "|   Sunny|29.0|         2| 15000|\n",
      "|  Pierre|35.0|        10| 40000|\n",
      "|  Benoit|55.0|        25| 75000|\n",
      "|   Lucas|45.0|        20| 64000|\n",
      "| Patrick|22.0|         2| 35000|\n",
      "|    NULL|21.0|         5| 40000|\n",
      "| Francis| 0.0|         0| 75000|\n",
      "|    NULL| 0.0|         0|     0|\n",
      "|    NULL|45.0|         0|     0|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remplace toutes les valeurs null par un string \"missing value\" ou une int '0'\n",
    "df_pyspark.na.fill(\"Missing value\").show()\n",
    "df_pyspark.na.fill(0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61bf893d-ac40-42db-9149-4933b84eb515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|   Krish|31.0|         5| 30000|\n",
      "|Sudhansh|30.0|        10| 10000|\n",
      "|   Sunny|29.0|         2| 15000|\n",
      "|  Pierre|35.0|        10| 40000|\n",
      "|  Benoit|55.0|        25| 75000|\n",
      "|   Lucas|45.0|        20| 64000|\n",
      "| Patrick|22.0|         2| 35000|\n",
      "|    NULL|21.0|         5| 40000|\n",
      "| Francis| 0.0|         0| 75000|\n",
      "|    NULL| 0.0|         0|  NULL|\n",
      "|    NULL|45.0|         0|  NULL|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remplace toutes les valeurs null de \"age\", \"Experience\" par un int \"0\"\n",
    "df_pyspark.na.fill(0, ['age', \"Experience\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbf4fc8-9b16-4dbb-bb5e-b35e288761e3",
   "metadata": {},
   "source": [
    "## Remplacement de valeur null par Imputation a la moyenne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bff0e09-7ca3-4d7f-bdbf-4a0c75a999b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['age', 'Experience', 'Salary'],\n",
    "    outputCols=[\"{}_imputed\".format(c) for c in ['age', 'Experience', 'Salary']]\n",
    ").setStrategy('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57843876-b3a7-46b7-ae2f-6cf31ad86638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+-----------------+------------------+--------------+\n",
      "|    Name| age|Experience|Salary|      age_imputed|Experience_imputed|Salary_imputed|\n",
      "+--------+----+----------+------+-----------------+------------------+--------------+\n",
      "|   Krish|31.0|         5| 30000|             31.0|                 5|         30000|\n",
      "|Sudhansh|30.0|        10| 10000|             30.0|                10|         10000|\n",
      "|   Sunny|29.0|         2| 15000|             29.0|                 2|         15000|\n",
      "|  Pierre|35.0|        10| 40000|             35.0|                10|         40000|\n",
      "|  Benoit|55.0|        25| 75000|             55.0|                25|         75000|\n",
      "|   Lucas|45.0|        20| 64000|             45.0|                20|         64000|\n",
      "| Patrick|22.0|         2| 35000|             22.0|                 2|         35000|\n",
      "|    NULL|21.0|         5| 40000|             21.0|                 5|         40000|\n",
      "| Francis|NULL|      NULL| 75000|34.77777777777778|                 9|         75000|\n",
      "|    NULL|NULL|      NULL|  NULL|34.77777777777778|                 9|         42666|\n",
      "|    NULL|45.0|      NULL|  NULL|             45.0|                 9|         42666|\n",
      "+--------+----+----------+------+-----------------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a70c59e-faf7-49a5-8c3c-1a27a1c8cf06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (python311)",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
